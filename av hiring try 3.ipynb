{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your client is a Financial Distribution company. Over the last 10 years, they have created an offline distribution channel across country. They sell Financial products to consumers by hiring agents in their network. These agents are freelancers and get commission when they make a product sale.\n",
    "\n",
    "\n",
    "\n",
    "Overview of your client On-boarding process\n",
    "The Managers at your client are primarily responsible for recruiting agents. Once a manager has identified a potential applicant, the would explain the business opportunity to the agent. Once the agent provides the consent, an application is made to your client to become an agent. This date is known as application_receipt_date.\n",
    "\n",
    "In the next 3 months, this potential agent has to undergo a 7 days training at the your client's branch (about Sales processes and various products) and clear a subsequent examination in order to become an agent.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The problem - Who are the best agents?\n",
    "As is obvious in the above process, there is a significant investment which your cleint makes in identifying, training and recruiting these agents. However, there are a set of agents who do not bring in the expected resultant business.\n",
    "\n",
    "Your client is looking for help from data scientists like you to help them provide insigths using their past recruitment data. They want to predict the target variable for each potential agent, which would help them identify the right agents to hire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ditictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Description\n",
    "Variable\tDefinition\n",
    "ID\tUnique Application ID\n",
    "Office_PIN\tPINCODE of Your client's Offices\n",
    "Application_Receipt_Date\tDate of Application\n",
    "Applicant_City_PIN\tPINCODE of Applicant Address\n",
    "Applicant_Gender\tApplicant's Gender\n",
    "Applicant_BirthDate\tApplicant's Birthdate\n",
    "Applicant_Marital_Status\tApplicant's Marital Status\n",
    "Applicant_Occupation\tApplicant's Occupation\n",
    "Applicant_Qualification\tApplicant's Educational Qualification\n",
    "Manager_DOJ\tManager's Date of Joining\n",
    "Manager_Joining_Designation\tManager's Joining Designation\n",
    "Manager_Current_Designation\tManager's Designation at the time of application sourcing\n",
    "Manager_Grade\tManager's Grade\n",
    "Manager_Status\tCurrent Employment Status (Probation / Confirmation)\n",
    "Manager_Gender\tManager's Gender\n",
    "Manager_DoB\tManager's Birthdate\n",
    "Manager_Num_Application\tNo. of Applications sourced in last 3 months by the Manager\n",
    "Manager_Num_Coded\tNo. of agents recruited by the manager in last 3 months\n",
    "Manager_Business\tAmount of business sourced by the manager in last 3 months\n",
    "Manager_Num_Products\tNumber of products sold by the manager in last 3 months\n",
    "Manager_Business2\tAmount of business sourced by the manager in last 3 months excluding business from their Category A advisor\n",
    "Manager_Num_Products2\tNumber of products sold by the manager in last 3 months excluding business from their Category A advisor\n",
    "Business_Sourced(Target)\tBusiness sourced by applicant within 3 months [1/0] of recruitment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.3 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (0.34.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (2.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.18.5)\n",
      "Requirement already satisfied: gast==0.3.3 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.1.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorflow==2.3) (1.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.21.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (49.4.0.post20200813)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\acer\\appdata\\roaming\\python\\python37\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\study\\great lakes\\intro to python\\anaconda\\envs\\py37\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\acer\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight,compute_sample_weight\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/Study/Hackathon analytics vidhya/Hackathon AV hiring  10092020'\n",
    "train_df=pd.read_csv(os.path.join(path,'train.csv'))\n",
    "test_df=pd.read_csv(os.path.join(path,'test.csv'))\n",
    "submission_df=pd.read_csv(os.path.join(path,'sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Business_Sourced'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df=train_df.drop_duplicates(subset=[ele for ele in list(train_df.columns) if ele not in ['ID']])\n",
    "#Adding more Features\n",
    "combine_set=pd.concat([train_df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le=LabelEncoder()\n",
    "\n",
    "\n",
    "combine_set['Applicant_City_PIN']=combine_set['Applicant_City_PIN'].fillna((combine_set['Applicant_City_PIN'].median())).astype('int')\n",
    "combine_set['Applicant_Gender'].fillna(combine_set['Applicant_Gender'].mode().iloc[0],inplace=True)\n",
    "combine_set['Applicant_Marital_Status'].fillna(combine_set['Applicant_Marital_Status'].mode().iloc[0],inplace=True)\n",
    "combine_set['Applicant_Occupation'].fillna('Missing',inplace=True)\n",
    "combine_set['Applicant_Qualification'].fillna(combine_set['Applicant_Qualification'].mode().iloc[0],inplace=True)\n",
    "\n",
    "combine_set['Manager_Joining_Designation'].fillna(combine_set['Manager_Joining_Designation'].mode().iloc[0],inplace=True)\n",
    "combine_set['Manager_Current_Designation'].fillna(combine_set['Manager_Current_Designation'].mode().iloc[0],inplace=True)\n",
    "combine_set['Manager_Grade'].fillna(combine_set['Manager_Grade'].median(),inplace=True)\n",
    "combine_set['Manager_Status'].fillna(combine_set['Manager_Status'].mode().iloc[0],inplace=True)\n",
    "combine_set['Manager_Gender'].fillna(combine_set['Manager_Gender'].mode().iloc[0],inplace=True)\n",
    "combine_set['Manager_Num_Application'].fillna(combine_set['Manager_Num_Application'].median(),inplace=True)\n",
    "combine_set['Manager_Num_Coded'].fillna(combine_set['Manager_Num_Coded'].median(),inplace=True)\n",
    "combine_set['Manager_Business'].fillna(combine_set['Manager_Business'].median(),inplace=True)\n",
    "combine_set['Manager_Num_Products'].fillna(combine_set['Manager_Num_Products'].median(),inplace=True)\n",
    "combine_set['Manager_Business2'].fillna(combine_set['Manager_Business2'].median(),inplace=True)\n",
    "combine_set['Manager_Num_Products2'].fillna(combine_set['Manager_Num_Products2'].median(),inplace=True)\n",
    "\n",
    "from datetime import datetime, date\n",
    "ref_date = datetime.now()\n",
    "# Date converion \n",
    "combine_set[[\"Application_Receipt_Date\", \"Applicant_BirthDate\", \"Manager_DOJ\",'Manager_DoB']] = combine_set[[\"Application_Receipt_Date\", \"Applicant_BirthDate\", \"Manager_DOJ\",'Manager_DoB']].apply(pd.to_datetime,errors ='coerce')\n",
    "\n",
    "# reciopt count freq encoding\n",
    "receipt_set=combine_set['Application_Receipt_Date'].value_counts().to_dict()\n",
    "combine_set['Application_Receipt_Date_Count']=combine_set['Application_Receipt_Date'].map(receipt_set)\n",
    "\n",
    "# NAT replacement\n",
    "combine_set['Applicant_BirthDate'] =  combine_set['Applicant_BirthDate'].astype(str)\n",
    "combine_set['Applicant_BirthDate'] = combine_set['Applicant_BirthDate'].apply(lambda x : ref_date if x==\"NaT\" else x)\n",
    "\n",
    "combine_set['Manager_DOJ'] =  combine_set['Manager_DOJ'].astype(str)\n",
    "combine_set['Manager_DOJ'] = combine_set['Manager_DOJ'].apply(lambda x : ref_date if x==\"NaT\" else x)\n",
    "\n",
    "combine_set['Manager_DoB'] =  combine_set['Manager_DoB'].astype(str)\n",
    "combine_set['Manager_DoB'] = combine_set['Manager_DoB'].apply(lambda x : ref_date if x==\"NaT\" else x)\n",
    "\n",
    "# Age Calculation\n",
    "combine_set['Applicant_Age'] = combine_set['Applicant_BirthDate'].apply(lambda x: len(pd.date_range(start = x, end = ref_date, freq = 'Y')))\n",
    "combine_set['Manager_Exp'] = combine_set['Manager_DOJ'].apply(lambda x: len(pd.date_range(start = x, end = ref_date, freq = 'Y')))\n",
    "combine_set['Manager_Age'] = combine_set['Manager_DoB'].apply(lambda x: len(pd.date_range(start = x, end = ref_date, freq = 'Y')))\n",
    "\n",
    "# Applicant age , manager experience and manager age feature imputed with median \n",
    "combine_set['Applicant_Age'].fillna(combine_set['Manager_Exp'].median(),inplace=True)\n",
    "combine_set['Manager_Exp'].fillna(combine_set['Manager_Exp'].median(),inplace=True)\n",
    "combine_set['Manager_Age'].fillna(combine_set['Manager_Age'].median(),inplace=True)\n",
    "\n",
    "#Droping date columns\n",
    "col = [\"Application_Receipt_Date\", \"Applicant_BirthDate\", \"Manager_DOJ\",'Manager_DoB']\n",
    "combine_set.drop(col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "combine_set1 = combine_set.copy()\n",
    "# Introducing two columns\n",
    "combine_set1['Manager_Actual_Business_ratio']=combine_set1['Manager_Business']-combine_set1['Manager_Business2']\n",
    "combine_set1['Manager_Num_Coded_ratio']=combine_set1['Manager_Num_Coded']-combine_set1['Manager_Num_Products2']\n",
    "combine_set1['Manager_Actual_Business_ratio'].fillna(combine_set1['Manager_Actual_Business_ratio'].median(),inplace=True)\n",
    "combine_set1['Manager_Num_Coded_ratio'].fillna(combine_set1['Manager_Num_Coded_ratio'].median(),inplace=True)\n",
    "\n",
    "# Applicant_City_PIN feature imputed with median \n",
    "combine_set1['Applicant_City_PIN'] = combine_set1['Applicant_City_PIN'].astype(str).str[:-5].astype(np.int64)\n",
    "\n",
    "# Applicant_City_PIN feature imputed with median\n",
    "combine_set1['Office_PIN'] = combine_set1['Office_PIN'].astype(str).str[:-5].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Manager_Joining_Designation feature imputed with mode & converted to categorical \n",
    "combine_set['Manager_Joining_Designation']=combine_set['Manager_Joining_Designation'].fillna('Designation_Unkown')\n",
    "combine_set['Manager_Joining_Designation']=le.fit_transform(combine_set['Manager_Joining_Designation'])\n",
    "\n",
    "# Manager_Joining_Designation feature imputed with mode & converted to categorical \n",
    "combine_set['Manager_Current_Designation']=combine_set['Manager_Current_Designation'].fillna('Current_Designation_Unkown')\n",
    "combine_set['Manager_Current_Designation']=le.fit_transform(combine_set['Manager_Current_Designation'])\n",
    "\n",
    "# Manager_Grade feature imputed with median \n",
    "combine_set['Manager_Grade']=le.fit_transform(combine_set['Manager_Grade'])\n",
    "\n",
    "# Manager_Joining_Designation feature imputed with mode & converted to categorical \n",
    "combine_set['Manager_Status']=combine_set['Manager_Status'].fillna('Manager_Status_Unkown')\n",
    "combine_set['Manager_Status']=le.fit_transform(combine_set['Manager_Status'])\n",
    "\n",
    "# Manager_Joining_Designation feature imputed with mode & converted to categorical \n",
    "combine_set['Manager_Status']=combine_set['Manager_Status'].fillna('Manager_Status_Unkown')\n",
    "combine_set['Manager_Status']=le.fit_transform(combine_set['Manager_Status'])\n",
    "\n",
    "# Manager_Grade feature imputed with median \n",
    "combine_set['Manager_Num_Application']=le.fit_transform(combine_set['Manager_Num_Application'])\n",
    "\n",
    "# Manager_Num_Coded feature imputed with median \n",
    "combine_set['Manager_Num_Coded']=le.fit_transform(combine_set['Manager_Num_Coded'])\n",
    "\n",
    "# Manager_Business feature imputed with median \n",
    "combine_set['Manager_Business']=le.fit_transform(combine_set['Manager_Business'])\n",
    "\n",
    "# Manager_Num_Products feature imputed with median \n",
    "combine_set['Manager_Num_Products']=le.fit_transform(combine_set['Manager_Num_Products'])\n",
    "\n",
    "# Manager_Business2 feature imputed with median \n",
    "combine_set['Manager_Business2']=le.fit_transform(combine_set['Manager_Business2'])\n",
    "\n",
    "# Manager_Num_Products2 feature imputed with median \n",
    "combine_set['Manager_Num_Products2']=le.fit_transform(combine_set['Manager_Num_Products2'])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# numeric columns\n",
    ">>> df.select_dtypes(include='float').fillna(\\\n",
    "     df.select_dtypes(include='float').mean().iloc[0],\\                    \n",
    "     inplace=True)\n",
    "\n",
    "# categorical columns\n",
    ">>> df.select_dtypes(include='object').fillna(\\\n",
    " ...: df.select_dtypes(include='object').mode().iloc[0])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_set1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_set1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE and le encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical Columns\n",
    "le=LabelEncoder()\n",
    "for col in combine_set1.select_dtypes(include='object').columns:\n",
    "    if col not in ['Business_Sourced']:\n",
    "#         fe=combine_set.groupby([col]).size()/len(combine_set)\n",
    "#         combine_set[col]=combine_set[col].apply(lambda x: fe[x])\n",
    "        df=pd.get_dummies(combine_set1[col],drop_first=True)\n",
    "        combine_set1=pd.concat([combine_set1,df],axis=1).drop([col],axis=1)\n",
    "          \n",
    "    elif col!='Business_Sourced':\n",
    "        combine_set[col]=le.fit_transform(combine_set[col].astype(str))\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "combine_set1.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=combine_set1[combine_set1['Business_Sourced'].isnull()==False].drop(['Business_Sourced'],axis=1)\n",
    "y=le.fit_transform(combine_set1[combine_set1['Business_Sourced'].isnull()==False]['Business_Sourced'])\n",
    "y=pd.DataFrame(y,columns=['Business_Sourced'])\n",
    "X_main_test=combine_set1[combine_set1['Business_Sourced'].isnull()==True].drop(['Business_Sourced'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_set1.to_csv(\"combine_set1_train_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_set1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # **Standardizing all Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=to_categorical(y)\n",
    "y_hat=pd.DataFrame(y_hat)\n",
    "sc_X=StandardScaler()\n",
    "X=sc_X.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "sc_X_main=StandardScaler()\n",
    "X_main_test=sc_X_main.fit_transform(X_main_test)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y_hat,test_size=0.2,random_state=294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequential NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "classifier.add(Dense(512,activation='relu', kernel_initializer='uniform',input_shape=(X_train.shape[1],)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(256,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dense(200,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dense(128,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dense(64,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dense(32,activation='relu',kernel_initializer='uniform'))\n",
    "classifier.add(Dense(11,activation='softmax'))\n",
    "\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "callback_lr=ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.3,min_lr=0.00001)\n",
    "callback_mc=ModelCheckpoint(filepath='model_repli.hdf5',monitor='val_accuracy',save_best_only=True,mode='max')\n",
    "\n",
    "classifier.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_val,y_val),callbacks=[callback_lr,callback_mc])\n",
    "\n",
    "classifier=load_model('model_repli.hdf5')\n",
    "pred_val=classifier.predict(X_val)\n",
    "\n",
    "preds=classifier.predict(X_main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier=Sequential()\n",
    "\n",
    "# classifier.add(Dense(512,activation='relu', kernel_initializer='uniform',input_shape=(X_train.shape[1],)))\n",
    "# classifier.add(Dropout(0.2))\n",
    "# classifier.add(Dense(256,activation='relu',kernel_initializer='uniform'))\n",
    "# # classifier.add(Dense(200,activation='relu',kernel_initializer='uniform'))\n",
    "# classifier.add(Dense(128,activation='relu',kernel_initializer='uniform'))\n",
    "# classifier.add(Dense(128,activation='relu',kernel_initializer='uniform'))\n",
    "# # classifier.add(Dense(32,activation='relu',kernel_initializer='uniform'))\n",
    "# classifier.add(Dense(11,activation='softmax'))\n",
    "\n",
    "# classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# callback_lr=ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.5,min_lr=0.00001)\n",
    "# callback_mc=ModelCheckpoint(filepath='model_reli2.hdf5',monitor='val_accuracy',save_best_only=True,mode='max')\n",
    "\n",
    "# classifier.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_val,y_val),callbacks=[callback_lr,callback_mc])\n",
    "\n",
    "# classifier=load_model('model_reli2.hdf5')\n",
    "# preds2_val=classifier.pedict(X_val)\n",
    "\n",
    "# preds2=classifier.predict(X_main_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # **KFOLD (LGBM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf=KFold(n_splits=10,shuffle=True,random_state=2020)\n",
    "# sc_X=StandardScaler()\n",
    "# X=pd.DataFrame(sc_X.fit_transform(X))\n",
    "preds={}\n",
    "acc_score=0\n",
    "\n",
    "    \n",
    "for i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n",
    "\n",
    "    X_train, y_train = X.iloc[train_idx,:], y_hat.iloc[train_idx]\n",
    "\n",
    "    X_val, y_val = X.iloc[val_idx, :], y_hat.iloc[val_idx]\n",
    "    \n",
    "\n",
    "    print('\\nFold: {}\\n'.format(i+1))\n",
    "    #12,0.8,1000\n",
    "    lg=LGBMClassifier(boosting_type='gbdt',learning_rate=0.08,depth=12,objective='multiclass',n_estimators=1000,num_class=11,\n",
    "                     metric='multi_error',colsample_bytree=0.5,reg_alpha=2,reg_lambda=2,random_state=294,n_jobs=-1)\n",
    "\n",
    "#     X_train,y_train=SMOTETomek(random_state=294).fit_resample(X_train,y_train)\n",
    "    lg.fit(X_train,y_train)\n",
    "\n",
    "    print(accuracy_score(y_val,lg.predict(X_val)))\n",
    "\n",
    "    acc_score+=accuracy_score(y_val,lg.predict(X_val))\n",
    "    \n",
    "    preds[i+1]=lg.predict(X_main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
