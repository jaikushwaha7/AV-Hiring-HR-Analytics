{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your client is a Financial Distribution company. Over the last 10 years, they have created an offline distribution channel across country. They sell Financial products to consumers by hiring agents in their network. These agents are freelancers and get commission when they make a product sale.\n",
    "\n",
    "\n",
    "\n",
    "Overview of your client On-boarding process\n",
    "The Managers at your client are primarily responsible for recruiting agents. Once a manager has identified a potential applicant, the would explain the business opportunity to the agent. Once the agent provides the consent, an application is made to your client to become an agent. This date is known as application_receipt_date.\n",
    "\n",
    "In the next 3 months, this potential agent has to undergo a 7 days training at the your client's branch (about Sales processes and various products) and clear a subsequent examination in order to become an agent.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The problem - Who are the best agents?\n",
    "As is obvious in the above process, there is a significant investment which your cleint makes in identifying, training and recruiting these agents. However, there are a set of agents who do not bring in the expected resultant business.\n",
    "\n",
    "Your client is looking for help from data scientists like you to help them provide insigths using their past recruitment data. They want to predict the target variable for each potential agent, which would help them identify the right agents to hire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ditictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Description\n",
    "Variable\tDefinition\n",
    "ID\tUnique Application ID\n",
    "Office_PIN\tPINCODE of Your client's Offices\n",
    "Application_Receipt_Date\tDate of Application\n",
    "Applicant_City_PIN\tPINCODE of Applicant Address\n",
    "Applicant_Gender\tApplicant's Gender\n",
    "Applicant_BirthDate\tApplicant's Birthdate\n",
    "Applicant_Marital_Status\tApplicant's Marital Status\n",
    "Applicant_Occupation\tApplicant's Occupation\n",
    "Applicant_Qualification\tApplicant's Educational Qualification\n",
    "Manager_DOJ\tManager's Date of Joining\n",
    "Manager_Joining_Designation\tManager's Joining Designation\n",
    "Manager_Current_Designation\tManager's Designation at the time of application sourcing\n",
    "Manager_Grade\tManager's Grade\n",
    "Manager_Status\tCurrent Employment Status (Probation / Confirmation)\n",
    "Manager_Gender\tManager's Gender\n",
    "Manager_DoB\tManager's Birthdate\n",
    "Manager_Num_Application\tNo. of Applications sourced in last 3 months by the Manager\n",
    "Manager_Num_Coded\tNo. of agents recruited by the manager in last 3 months\n",
    "Manager_Business\tAmount of business sourced by the manager in last 3 months\n",
    "Manager_Num_Products\tNumber of products sold by the manager in last 3 months\n",
    "Manager_Business2\tAmount of business sourced by the manager in last 3 months excluding business from their Category A advisor\n",
    "Manager_Num_Products2\tNumber of products sold by the manager in last 3 months excluding business from their Category A advisor\n",
    "Business_Sourced(Target)\tBusiness sourced by applicant within 3 months [1/0] of recruitment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e02f99bbb28a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import tensorflow as tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Great Lakes\\INtro to python\\Anaconda\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf \n",
    "import keras\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight,compute_sample_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/Study/Hackathon analytics vidhya/Hackathon AV hiring  10092020'\n",
    "train_df=pd.read_csv(os.path.join(path,'train.csv'))\n",
    "test_df=pd.read_csv(os.path.join(path,'test.csv'))\n",
    "submission_df=pd.read_csv(os.path.join(path,'sample.csv'))\n",
    "combine_set1 =pd.read_csv(os.path.join(path,'combine_data_train_test5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=combine_set1[combine_set1['Business_Sourced'].isnull()==False].drop(['Business_Sourced'],axis=1)\n",
    "y=le.fit_transform(combine_set1[combine_set1['Business_Sourced'].isnull()==False]['Business_Sourced'])\n",
    "y=pd.DataFrame(y,columns=['Business_Sourced'])\n",
    "X_main_test=combine_set1[combine_set1['Business_Sourced'].isnull()==True].drop(['Business_Sourced'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=to_categorical(y)\n",
    "y_hat=pd.DataFrame(y_hat)\n",
    "sc_X=StandardScaler()\n",
    "X=sc_X.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "sc_X_main=StandardScaler()\n",
    "X_main_test=sc_X_main.fit_transform(X_main_test)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y_hat,test_size=0.2,random_state=294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=10,shuffle=True,random_state=2020)\n",
    "# sc_X=StandardScaler()\n",
    "# X=pd.DataFrame(sc_X.fit_transform(X))\n",
    "preds={}\n",
    "acc_score=0\n",
    "\n",
    "    \n",
    "for i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n",
    "\n",
    "    X_train, y_train = X.iloc[train_idx,:], y_hat.iloc[train_idx]\n",
    "\n",
    "    X_val, y_val = X.iloc[val_idx, :], y_hat.iloc[val_idx]\n",
    "    \n",
    "\n",
    "    print('\\nFold: {}\\n'.format(i+1))\n",
    "    #12,0.8,1000\n",
    "    lg=LGBMClassifier(boosting_type='gbdt',learning_rate=0.08,depth=12,objective='binary',n_estimators=1000,num_class=11,\n",
    "                     metric='binary_logloss',colsample_bytree=0.5,reg_alpha=2,reg_lambda=2,random_state=294,n_jobs=-1)\n",
    "\n",
    "#     X_train,y_train=SMOTETomek(random_state=294).fit_resample(X_train,y_train)\n",
    "    lg.fit(X_train,y_train)\n",
    "\n",
    "    print(accuracy_score(y_val,lg.predict(X_val)))\n",
    "\n",
    "    acc_score+=accuracy_score(y_val,lg.predict(X_val))\n",
    "    \n",
    "    preds[i+1]=lg.predict(X_main_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "df1 = X.copy()\n",
    "\n",
    "X=df1.drop('Business_Sourced',1)\n",
    "y=df1['Business_Sourced']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =1)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier()\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "# ab_rf = AdaBoostClassifier(base_estimator=rf,random_state=0)\n",
    "# ab_dt = AdaBoostClassifier(base_estimator=dt,random_state=0)\n",
    "# ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# ab_lr=  AdaBoostClassifier(base_estimator=lr,random_state=0)\n",
    "bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0)\n",
    "\n",
    "# ,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr\n",
    "\n",
    "models=[lr,rf,adb,bgc,gnb,knn,dt,bgcl_lr]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            y_test_pred_new=model.predict_proba(X_test)\n",
    "            y_test_pred_new=y_test_pred_new[:,1]\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            \n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n",
    "            \n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "# 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Naive-Bayes','KNN','Decistion Tree',\n",
    "                                'bagged LR'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by='auc_score',ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making predictions:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb=AdaBoostClassifier()\n",
    "\n",
    "adb.fit(X,y)\n",
    "y_test_pred_adb=adb.predict(dfte1)\n",
    "\n",
    "finalpred=pd.concat([dfte['ID'],pd.DataFrame(y_test_pred_adb,columns=['Business_Sourced'])],1)\n",
    "finalpred.to_csv(\"submission_adbpred2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(learning_rate=0.09,n_estimators=125,max_depth=4,min_child_weight=4,colsample_bytree=0.5,reg_alpha=0.000001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X,y)\n",
    "y_test_pred_xgb=xgb.predict(X_main_test)\n",
    "finalpred=pd.concat([dfte['ID'],pd.DataFrame(y_test_pred_xgb,columns=['Business_Sourced'])],1)\n",
    "finalpred.to_csv(\"xgbpred2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
